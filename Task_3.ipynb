{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpKV99sacZxuuDUiN/8PH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ketan-Suke/-PRODIGY_ML_03-/blob/main/Task_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqbeA1Esw-8C",
        "outputId": "f9f5318b-6b65-422b-97b0-2180c95f2f5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "imagePaths = []\n",
        "labels = []\n",
        "for root,dirnames,filenames in os.walk('/content/drive/MyDrive/INTERNSHIP-prodgy/Cat vs Dog'):\n",
        "  for filename in filenames:\n",
        "    if filename.lower().endswith(('png','jpeg','jpg')):\n",
        "       imagePaths.append(os.path.join(root, filename))\n",
        "\n",
        "       labels.append(root[74:])\n",
        "\n",
        "print(len(labels))\n",
        "print(len(imagePaths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXj3xXMty7e5",
        "outputId": "c4d25531-bedb-4d74-a62a-c64599f79275"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "328\n",
            "328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Define paths to dataset folders\n",
        "dataset_path = \"/content/drive/MyDrive/INTERNSHIP-prodgy/Cat vs Dog\"\n",
        "train_dir = os.path.join(dataset_path, \"/content/drive/MyDrive/INTERNSHIP-prodgy/Cat vs Dog/train\")\n",
        "test_dir = os.path.join(dataset_path, \"/content/drive/MyDrive/INTERNSHIP-prodgy/Cat vs Dog/test\")\n",
        "val_dir = os.path.join(dataset_path, \"/content/drive/MyDrive/INTERNSHIP-prodgy/Cat vs Dog/validation\")\n",
        "\n",
        "# Image preprocessing\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "def load_data(directory):\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "    return generator\n",
        "\n",
        "train_generator = load_data(train_dir)\n",
        "test_generator = load_data(test_dir)\n",
        "val_generator = load_data(val_dir)\n",
        "\n",
        "# Load MobileNetV2 for feature extraction\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "base_model.trainable = False  # Freeze the model\n",
        "\n",
        "def extract_features(generator):\n",
        "    features, labels = [], []\n",
        "    for batch_images, batch_labels in generator:\n",
        "        batch_features = base_model.predict(batch_images)\n",
        "        batch_features = batch_features.reshape(batch_features.shape[0], -1)\n",
        "        features.append(batch_features)\n",
        "        labels.append(batch_labels)\n",
        "        if len(features) * batch_size >= generator.samples:\n",
        "            break\n",
        "    return np.vstack(features), np.hstack(labels)\n",
        "\n",
        "# Extract features from datasets\n",
        "X_train, y_train = extract_features(train_generator)\n",
        "X_test, y_test = extract_features(test_generator)\n",
        "X_val, y_val = extract_features(val_generator)\n",
        "\n",
        "# Train SVM classifier\n",
        "svm = SVC(kernel='linear', C=1.0)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_pred = svm.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(classification_report(y_test, y_pred, target_names=['Cat', 'Dog']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0b91KZ4q76B",
        "outputId": "321f217e-28f9-41b6-b412-508bfabb9086"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 86 images belonging to 2 classes.\n",
            "Found 42 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Test Accuracy: 0.7857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Cat       0.75      0.86      0.80        21\n",
            "         Dog       0.83      0.71      0.77        21\n",
            "\n",
            "    accuracy                           0.79        42\n",
            "   macro avg       0.79      0.79      0.78        42\n",
            "weighted avg       0.79      0.79      0.78        42\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-J-NPi7ardJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}